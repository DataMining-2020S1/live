<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>BSc - Data Mining 1</title>

    <!-- Bootstrap core CSS -->
    <link href="../../../style/bootstrap/css/bootstrap.min.css" rel="stylesheet">
<link href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="../../../style/codehilite/css/default.css" rel="stylesheet">
    <link href="../../../style/misc/css/module.css" rel="stylesheet">
    <link href="../../../style/misc/css/practical.css" rel="stylesheet">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

	<script type="text/javascript"
	  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script>

  </head>

<body>

	<!-- Fixed navbar -->
	<div class="navbar navbar-default navbar-fixed-top" role="navigation">
		<div class="container">
			
			
	    	<div class="collapse navbar-collapse">

				<ul class="nav navbar-nav navbar-left">
					<!-- Moodle -->
					<li>
						<div class="navbar-header">
							<a class="navbar-brand" href="https://moodle.wit.ie/course/view.php?id=182859" target="_blank"><img height="18pt" src="../../../style/misc/img/moodle_logo_on_blue.gif" /></a>
						</div>						
					</li>
				</ul>

	      		<ul class="nav navbar-nav navbar-right">

					<!-- module home -->
					<li>
						<div class="navbar-header">
							<a class="navbar-brand" href="../../../index.html"><span class="glyphicon glyphicon-home"></span></a>
						</div>						
					</li>
					
					<!-- topics -->
	        		<li>
						<div class="navbar-collapse collapse" id="b">
							<ul class="nav navbar-nav">
								<li class="dropdown">
									<a href="#" class="dropdown-toggle" data-toggle="dropdown">
										<span class="glyphicon glyphicon-list-alt"></span>
									</a>
									<ul class="dropdown-menu" role="menu">
										<li class="dropdown-header">Topics</li>
										
										<li >
											<a href="../../../topics/01-Module_Overview/index.html">Module Overview</a>
										</li>
										
										<li >
											<a href="../../../topics/02-Motivating_Example/index.html">Motivating Example</a>
										</li>
										
										<li class="active">
											<a href="../../../topics/03-Data_Handling/index.html">Data Handling</a>
										</li>
										
									</ul>
								</li>
							</ul>
						</div>			
					</li>

					<!-- resources -->
	        		<li>
						<div class="navbar-collapse collapse" id="b">
							<ul class="nav navbar-nav">
								<li class="dropdown">
									<a href="#" class="dropdown-toggle" data-toggle="dropdown">
										<span class="glyphicon glyphicon-th-list"></span>
									</a>
									<ul class="dropdown-menu" role="menu">
										<li class="dropdown-header">Resources</li>
										
										<li >
											<a href="../../../topics/03-Data_Handling/index.html#01-Data-Storage">Data-Storage</a>
										</li>
										
										<li >
											<a href="../../../topics/03-Data_Handling/index.html#02-Big-Data-Frameworks">Big-Data-Frameworks</a>
										</li>
										
										<li >
											<a href="../../../topics/03-Data_Handling/index.html#04-Resources.tar.xz">Resources.tar.xz</a>
										</li>
										
										<li class="active">
											<a href="../../../topics/03-Data_Handling/index.html#10-Practical">Practical</a>
										</li>
										
									</ul>
								</li>
							</ul>
						</div>			
					</li>
								
					<!-- pages-->
	        		<li>
						<div class="navbar-collapse collapse" id="c">
							<ul class="nav navbar-nav">
								<li class="dropdown">
									<a href="#" class="dropdown-toggle" data-toggle="dropdown">
										<span>Installation</span
									</a>
									<ul class="dropdown-menu" role="menu">
										
										<li >
											<a href="00-Outline.html">Outline</a>
										</li>
										
										<li class="active">
											<a href="01-Installation.html">Installation</a>
										</li>
										
										<li >
											<a href="02-Spark_Examples.html">Spark Examples</a>
										</li>
										
									</ul>
								</li>
							</ul>
						</div>			
					</li> 
					
	        	</ul>
			</div>
		</div>
	</div>

	<!-- contents -->
	<div class="container">
		
		<ul class="pager">
			
			<li class="previous"><a href="00-Outline.html">&larr; Previous (Outline)</a></li>
			
			
			
			<li class="next"><a href="02-Spark_Examples.html">Next (Spark Examples) &rarr;</a></li>
			
		</ul>
		
		<h2>Installing Spark on Windows</h2>
<p>For MS Windows machines, <a href="https://phoenixnap.com/kb/install-spark-on-windows-10">this guide</a> goes through all
the necessary steps. That guide should be followed with the following
exceptions:</p>
<ol>
<li>
<p>The Spark version we use is Spark 3.1.2, compiled with Scala 2.12 and
prebuilt for Apache Hadoop 3.2 and later.</p>
</li>
<li>
<p>After a Java 8 JVM has been installed, it might not seem to be necessary to
install Scala too - the Spark installation seems to have as much Scala as it
needs</p>
</li>
<li>
<p>You have already installed python using either Anaconda or Miniconda. You
should just ensure that it has been activated using 'conda activate`.</p>
</li>
</ol>
<h2>Installing Spark on Macos and Linux</h2>
<p>The download page is <a href="https://spark.apache.org/downloads.html">here</a>.</p>
<p>From the dropdown, use <code>Spark Release 3.1.2 (Jun 01 2021)</code> and <code>Pre-built for
Apache Hadoop 3.2 and later</code>.</p>
<p>Clicking on
<a href="https://www.apache.org/dyn/closer.lua/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz">spark-3.1.2-bin-hadoop3.2.tgz</a>
takes you to a page that describes the necessary steps.</p>
<p>You can download the archive from the nearest mirror as suggested by Apache.</p>
<p>You should also download the <a href="https://downloads.apache.org/spark/KEYS">signing keys</a>, <a href="https://downloads.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz.sha512">sha512 checksum</a>
and <a href="https://downloads.apache.org/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz.asc">GnuPG signature</a>.</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="nb">cd</span> ~/Downloads <span class="c1"># or wherever you downloaded the spark archive, sha512 sum, KEYS and gpg signature</span>
gpg --import KEYS
<span class="nv">f</span><span class="o">=</span>spark-3.1.2-bin-hadoop3.2.tgz
gpg --verify <span class="si">${</span><span class="nv">f</span><span class="si">}</span>.asc <span class="nv">$f</span>
</code></pre></div>
</td></tr></table>
<p>The resulting report should say something like <code>Good signature from ...</code>.</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="nv">local</span><span class="o">=</span><span class="sb">`</span>mktemp<span class="sb">`</span>
gpg --print-md SHA512 <span class="nv">$f</span> &gt; <span class="nv">$local</span>
diff <span class="nv">$local</span> <span class="si">${</span><span class="nv">f</span><span class="si">}</span>.sha512 <span class="p">&amp;</span>&gt; /dev/null <span class="o">&amp;&amp;</span> <span class="nb">echo</span> <span class="s2">&quot;Hashes match :-)&quot;</span> <span class="o">||</span> <span class="nb">echo</span> <span class="s2">&quot;Hashes don&#39;t match :-(&quot;</span>
</code></pre></div>
</td></tr></table>
<p>The message should read <code>Hashes match :-)</code>.</p>
<p>Assuming all is well, you should decompress the archive so that it is ready for
use.</p>
<h2>Install pyspark</h2>
<p>Spark was designed with the Scala language in mind, but we use python in this
module. Hence we suggest that the <code>pyspark</code> module is used to bridge between
the Spark/scala world and the python programs and tools we use in this module.
With pyspark in place, Spark can be called from python (the default is to use
scala and its shell to invoke Spark)</p>
<p>You can install pyspark using conda. If you install in your working conda
environment, it can take a very long time to resolve dependencies, although it
successed eventually.</p>
<p>Since pyspark is useful only in the context of big data/spark, it makes sense
to create a <code>spark</code> environment and install it there. You can then install
<code>pyspark</code> with little risk of package inconsistencies.</p>
<p>To install, create the new environment with python 3.8 and <code>pyspark</code>. For
Jupyter notebook support, we also install <code>findspark</code>and <code>jupyter</code>. Note that
spark provides the remaining machine learning functionalities through its
<code>mllib</code>:</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>conda create --name spark <span class="nv">python</span><span class="o">=</span><span class="m">3</span>.8 pyspark
conda install -c conda-forge -y findspark
conda install -c conda-forge -y jupyter
conda activate spark
</code></pre></div>
</td></tr></table>
<h1>Check that Spark server can be started OK</h1>
<p>The following starts a Spark shell (mote precisely: a scala shell with Spark
running on localhost with 2 threads, usually mapped as 1 thread per processor
core):</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code><span class="nb">cd</span> spark-3.1.2-bin-hadoop3.2
<span class="nv">nThread</span><span class="o">=</span><span class="m">2</span>
./bin/spark-shell --master local<span class="o">[</span><span class="nv">$nThread</span><span class="o">]</span>
</code></pre></div>
</td></tr></table>
<p>See screen shot of <code>spark-shell</code> below.</p>
<figure>
  <img src="files/sparkShell.png" alt="" width="80%" >
  <figcaption>spark-shell screenshot, with commands aqvailoable in this shell.</figcaption>
</figure>

<p>Using the scala REPL shell requires knowledge of scala to be productive. If you
are not familar with scala, it is probably easier at this point to close the
(scala) spark shell, using either <code>:q</code> or <code>sys.exit</code>.</p>
<h1>Check that Spark can run <em>scala</em> jobs</h1>
<p>Run the "classic" Spark example of estimating <code>pi</code> based on estimating the area
of a disk of unit radius (which is <code>pi</code> by definition).</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span>
<span class="normal">2</span>
<span class="normal">3</span>
<span class="normal">4</span>
<span class="normal">5</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>./bin/spark-submit <span class="se">\</span>
  --class org.apache.spark.examples.SparkPi <span class="se">\</span>
  --master local<span class="o">[</span><span class="nv">$nThread</span><span class="o">]</span> <span class="se">\</span>
  ./examples/jars/spark-examples_2.12-3.1.2.jar <span class="se">\</span>
  <span class="m">10</span>
</code></pre></div>
</td></tr></table>
<h1>Check that Spark can run <em>python</em> jobs</h1>
<p>It might be easier to use the pyspark included in the Spark distribution to
interact with Spark directly, using python rather than scala. The equivalent
invocation of the Python-based SparkPi example is</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>./bin/spark-submit examples/src/main/python/pi.py <span class="m">10</span>
</code></pre></div>
</td></tr></table>
<p>where <code>spark-submit</code> uses <code>pyspark</code> behind the scenes to handle python-based
jobs.</p>
<p>Indeed, <code>pyspark</code> can be used more directly to provide a python shell that can
be used to start and stop Spark and to control its operations:</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>./bin/pyspark --master local<span class="o">[</span><span class="nv">$nThread</span><span class="o">]</span>
</code></pre></div>
</td></tr></table>
<p>Or you can use the pyspark installed using conda: (assuming you have already
activated the <code>spark</code> environment)</p>
<table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">1</span></pre></div></td><td class="code"><div class="highlight"><pre><span></span><code>pyspark --master local<span class="o">[</span><span class="nv">$nThread</span><span class="o">]</span>
</code></pre></div>
</td></tr></table>
<p>See screen shot of pyspark shell below.</p>
<figure>
  <img src="files/pyspark.png" alt="" width="80%" >
  <figcaption>pyspark screenshot, before python commands are added in this shell.</figcaption>
</figure>

<p>You can issue python commands as usual, but also have access to the Spark API,
to create a Spark instance and interact with the SparkContext object.</p>
		
		<ul class="pager">
			
			<li class="previous"><a href="00-Outline.html">&larr; Previous (Outline)</a></li>
			
			
			
			<li class="next"><a href="02-Spark_Examples.html">Next (Spark Examples) &rarr;</a></li>
			
		</ul>

	</div>
	
    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
    <script src="../../../style/bootstrap/js/bootstrap.min.js"></script>
	
  </body>
</html>